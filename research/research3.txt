ì´ë²ˆ ëŒ€íšŒ ë§Žì€ ë¶„ë“¤ì´ ì°¸ì—¬í•˜ì…¨ëŠ”ë°, ë‹¤ì‹œ í•œë²ˆ ìˆ˜ê³  ë§Žìœ¼ì…¨ìŠµë‹ˆë‹¤. ë•ë¶„ì— ë§Žì´ ë°°ì›Œê°‘ë‹ˆë‹¤.
ê¸°ì¡´ í† í¬ì— ì˜¬ë ¸ë“¯ ì €í¬ëŠ” UnderSampling ì „ëžµì„ ì‚¬ìš©í•´ì„œ

- CatBoost 1:1 (3 seed ensemble)
- XGBoost 10:1 (3 seed ensemble)
- FiBiNet 10:1 (5 split ensemble)

ì „ëžµì„ ì‚¬ìš©í•´ ê°ê° 40:35:25ë¡œ ì•™ìƒë¸”ì„ í–ˆìŠµë‹ˆë‹¤.

ê° ëª¨ë¸ì€ ë‹¨ì¼ë¡œ ì‚¬ìš©ì‹œ public score 0.3498 ì •ë„ ë‚˜ì˜¤ê³ , ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ 0.3478ì •ë„ ë‚˜ì™”ë˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
CatBoostì™€ XGBoostê°€ ë¹„ìœ¨ì°¨ì´ê°€ ìžˆë‹¤ë³´ë‹ˆ ê°ê° í‰ê°€ì§€í‘œì—ì„œì˜ ê°•ì ì´ ë‹¬ëžê³ , ì´ë¥¼ ì•™ìƒë¸” í–ˆì„ ë•Œ ë§Žì€ ì„±ëŠ¥ ìƒìŠ¹ì´ ìžˆì—ˆìŠµë‹ˆë‹¤. (0.3510)
ë˜í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¤‘ FiBiNetì„ ë³´ì¡°ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì„±ëŠ¥ ë³€ë™ì„ ìµœì†Œí™” ì‹œì¼°ìŠµë‹ˆë‹¤. (0.3513)

íŒŒìƒë³€ìˆ˜ ìµœëŒ€í•œ ì „ CTR ëŒ€íšŒë¥¼ ì°¸ê³ í•˜ì—¬ ì œìž‘í•˜ì˜€ê³ , í”¼ì³ ìž„í¬í„´ìŠ¤ì™€ í†µê³„ì  ìˆ˜ì¹˜ë“¤ì„ ê³ ë ¤í•´

- ìƒí˜¸ìž‘ìš© ë³€ìˆ˜: ë²”ì£¼í˜• ê¸°ë°˜ 10ê°œ
- seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜: seq_pos, seq_neg, seq_prob, seq_len
- count_encoding: ì¹´ë””ë„ë¦¬í‹°ê°€ ë§Žì´ ì¡´ìž¬í•˜ëŠ” ë³€ìˆ˜ì— ì ìš©
- mean,std í†µê³„ëŸ‰ ê¸°ë°˜ íŒŒìƒë³€ìˆ˜: ëª¨ë¸ë³„ í”¼ì³ ì¸í¬í„´ìŠ¤ ê¸°ë°˜ ì ìš©

ë‹¤ìŒê³¼ ê°™ì€ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë¶„ì„ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.

ë‹¤ë“¤ ëŒ€ê·œëª¨ ë°ì´í„°ì´ê¸°ì— ë¶„ì„ì´ íž˜ë“¤ë‹¤ëŠ” ì˜ê²¬ì´ ë§Žì•˜ê³ , ì €ë„ ì „ì— ì§„í–‰í–ˆë˜ ì¹´ë“œ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€íšŒì—ì„œ ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì¸í•œ ìžì› ë¬¸ì œê°€ ê³„ì† ë°œìƒí•´ì„œ
ì´ë²ˆì—ëŠ” ê³ ì‚¬ì–‘ GPUê°€ ì•„ë‹ˆì—¬ë„ ë¶„ì„ ê°€ëŠ¥í•œ ì½”ë“œë¥¼ ë§Œë“œë ¤ê³  ë…¸ë ¥ì„ ë§Žì´ í–ˆìŠµë‹ˆë‹¤. (XGB + CBT model CPU ì‚¬ìš©ì‹œ ì˜µíŠœë‚˜ í¬í•¨ 8ì‹œê°„ ë¯¸ë§Œ ì¶”ë¡ )

ì½”ë“œ ì¼ë¶€ë§Œ ì—¬ê¸°ì— ê³µê°œë¥¼ í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ê¹ƒí—ˆë¸Œë¥¼ í†µí•´ ê³µê°œí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ë“¤ ìˆ˜ê³  ë§Žìœ¼ì…¨ìŠµë‹ˆë‹¤.
- https://github.com/woglewagle/-NEXT-ML-CHALLENGE-CTR-

ì½”ë“œ

!pip install xgboost optuna openpyxl -q
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0.0/400.9 kB ? eta -:--:--
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 400.9/400.9 kB 13.2 MB/s eta 0:00:00

# Colab drive ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# ê¸°ë³¸ ìœ í‹¸ë¦¬í‹°
import os
import random
import gc
from itertools import combinations
from collections import defaultdict

# ë°ì´í„° ì²˜ë¦¬
import numpy as np
import pandas as pd
from tqdm import tqdm

# PyTorch
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import IterableDataset, DataLoader

# ML & í‰ê°€
import xgboost as xgb
import optuna
from optuna.samplers import TPESampler
from sklearn.model_selection import train_test_split
from sklearn.metrics import average_precision_score, log_loss

# íŒŒì¼ ìž…ì¶œë ¥
import joblib
import zipfile
import ast
Mounted at /content/drive
File Setting

# ===================================================
# í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ===================================================
DATA_PATH = '/content/drive/MyDrive/toss/'
SEEDS = [42, 1031, 106]   # ì‹œë“œ ë¦¬ìŠ¤íŠ¸
RATIOS = [1, 10]       # 1:1, 10:1 ë¹„ìœ¨
OUTPUT_PATH = DATA_PATH   # toss/ í´ë” ë°”ë¡œ ì‚¬ìš©
os.makedirs(OUTPUT_PATH, exist_ok=True)

# ===================================================
# Seed ê³ ì • í•¨ìˆ˜
# ===================================================
def seed_everything(seed: int):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)

# ===================================================
# ì‹œë“œ + ë¹„ìœ¨ë³„ ë‹¤ìš´ìƒ˜í”Œë§ ë° ì €ìž¥
# ===================================================
for seed in SEEDS:
    print(f"\n========== SEED {seed} ì‹¤í–‰ ==========")
    seed_everything(seed)

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    train_df = pd.read_parquet(os.path.join(DATA_PATH, "train.parquet"))

    clicked_1 = train_df[train_df['clicked'] == 1]
    total_1 = len(clicked_1)

    for ratio in RATIOS:
        n_0 = total_1 * ratio  # í´ëž˜ìŠ¤ 0 ê°œìˆ˜ = í´ëž˜ìŠ¤ 1 * ratio
        clicked_0 = train_df[train_df['clicked'] == 0].sample(
            n=n_0, replace=True if n_0 > len(train_df[train_df['clicked']==0]) else False,
            random_state=seed
        )

        train_df_down = pd.concat([clicked_1, clicked_0], axis=0)\
                          .sample(frac=1, random_state=seed)\
                          .reset_index(drop=True)

        # ì €ìž¥
        save_path = os.path.join(OUTPUT_PATH, f"train_{seed}_{ratio}.parquet")
        train_df_down.to_parquet(save_path, index=False)
        print(f"[SEED {seed} | Ratio {ratio}:1] Down-sampled Train saved at: {save_path} "
              f"(Class1: {len(clicked_1)}, Class0: {len(clicked_0)})")

# ===================================================
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ===================================================
train_df = pd.read_parquet(os.path.join(DATA_PATH, 'train.parquet'))

# ===================================================
# 2. ìˆ«ìžë³„ clicked í†µê³„ ê³„ì‚° (í•œ í–‰ ì¤‘ë³µ ì œê±°)
# ===================================================
number_clicks = defaultdict(lambda: [0, 0])  # [ì´ ë“±ìž¥ íšŸìˆ˜, í´ë¦­ëœ íšŸìˆ˜]

for _, row in train_df.iterrows():
    seq_str = row['seq']
    clicked = row['clicked']

    if pd.isna(seq_str) or seq_str == '':
        continue

    # í•œ í–‰ì—ì„œ ì¤‘ë³µ ì œê±°
    numbers = set(int(x) for x in seq_str.split(',') if x)

    for num in numbers:
        number_clicks[num][0] += 1      # ì´ ë“±ìž¥ íšŸìˆ˜
        number_clicks[num][1] += clicked  # ì´ í´ë¦­ íšŸìˆ˜

# ===================================================
# 3. DataFrame ë³€í™˜
# ===================================================
data = []
for num, (total_count, clicked_count) in number_clicks.items():
    click_prob = clicked_count / total_count if total_count > 0 else 0
    data.append([num, click_prob, total_count, clicked_count])

df_numbers = pd.DataFrame(data, columns=['number', 'click_prob', 'total_count', 'clicked_count'])

# ===================================================
# 4. í´ë¦­ í™•ë¥  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
# ===================================================
df_numbers = df_numbers.sort_values(by='click_prob', ascending=False).reset_index(drop=True)

# ===================================================
# 5. ì—‘ì…€ë¡œ ì €ìž¥
# ===================================================
df_numbers.to_excel(os.path.join(OUTPUT_PATH, 'high_click_numbers.xlsx'), index=False)
File Load

import pandas as pd

# ========================
# 1. ê¸°ë³¸ ê²½ë¡œ ë° íŒŒì¼ëª… ì •ì˜
# ========================
base_path = "/content/drive/MyDrive/toss/"
file_names = [
    "train_106_10.parquet",
    "train_1031_10.parquet",
    "train_42_10.parquet",
    "test.parquet"
]

# ========================
# 2. ë¶ˆëŸ¬ì˜¤ê¸° + ì´ë¦„ ë§¤í•‘
# ========================
datasets = {}
for i, fname in enumerate(file_names, start=1):
    df = pd.read_parquet(base_path + fname)
    if "test" in fname:
        key = "test"
    else:
        key = f"train_{i:02d}"
    datasets[key] = df
    print(f"[Loaded] {key} | shape={df.shape}")

# ========================
# 3. ì ‘ê·¼ ì˜ˆì‹œ
# ========================
train_01 = datasets["train_01"]
train_02 = datasets["train_02"]
train_03 = datasets["train_03"]
test     = datasets["test"]
[Loaded] train_01 | shape=(2245969, 120)
[Loaded] train_02 | shape=(2245969, 120)
[Loaded] train_03 | shape=(2245969, 120)
[Loaded] test | shape=(1527298, 119)
Data Processing

# ========================
# í•¨ìˆ˜ ì •ì˜
# ========================
def create_combination_features(df):

    base_cols = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']
    combo_features = {}

    # ëª¨ë“  2ì»¬ëŸ¼ ì¡°í•© ìƒì„±
    for col_a, col_b in combinations(base_cols, 2):
        combo_name = f'{col_a}_{col_b}'
        combo_features[combo_name] = (df[col_a].astype(str) + '_' + df[col_b].astype(str)).astype(object)

    # ë³‘í•©
    combo_df = pd.DataFrame(combo_features, index=df.index)
    df = pd.concat([df, combo_df], axis=1)

    print(f"âœ… ë²”ì£¼í˜• ê¸°ë°˜ ìƒí˜¸ìž‘ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: {df.shape[1]})")
    return df

# ========================
# ì ìš©
# ========================
train_01 = create_combination_features(train_01)
train_02 = create_combination_features(train_02)
train_03 = create_combination_features(train_03)
test     = create_combination_features(test)
âœ… ë²”ì£¼í˜• ê¸°ë°˜ ìƒí˜¸ìž‘ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 130)
âœ… ë²”ì£¼í˜• ê¸°ë°˜ ìƒí˜¸ìž‘ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 130)
âœ… ë²”ì£¼í˜• ê¸°ë°˜ ìƒí˜¸ìž‘ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 130)
âœ… ë²”ì£¼í˜• ê¸°ë°˜ ìƒí˜¸ìž‘ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 129)

# ===================================================
# 1. í´ë¦­ í™•ë¥  í…Œì´ë¸” ë¶ˆëŸ¬ì˜¤ê¸°
# ===================================================
df_click_prob = pd.read_excel(os.path.join(base_path, 'high_click_numbers.xlsx'))
click_prob_map = dict(zip(df_click_prob['number'], df_click_prob['click_prob']))

# ===================================================
# 2. ë¶€ì •/ê¸ì • ë¦¬ìŠ¤íŠ¸
# ===================================================
pos_list = {370, 528, 68, 561, 144, 227, 417, 442, 186, 395}
neg_list = {154, 222, 84, 498, 434, 511, 216, 497, 309, 446}

# ===================================================
# 3. í•¨ìˆ˜ ì •ì˜
# ===================================================
def add_seq_features(df, name="dataset"):
    seq_len, avg_prob, seq_neg, seq_pos = [], [], [], []

    for s in df["seq"]:
        if isinstance(s, str) and s != "":
            arr = [int(x) for x in s.split(",") if x]

            # ê¸¸ì´
            seq_len.append(len(arr))

            # í´ë¦­ í™•ë¥  í‰ê· 
            probs = [click_prob_map[num] for num in arr if num in click_prob_map]
            avg_prob.append(sum(probs) / len(probs) if probs else np.nan)

            # neg/pos ì¹´ìš´íŠ¸
            seq_neg.append(sum(1 for x in arr if x in neg_list))
            seq_pos.append(sum(1 for x in arr if x in pos_list))
        else:
            seq_len.append(0)
            avg_prob.append(np.nan)
            seq_neg.append(0)
            seq_pos.append(0)

    df["seq_len"] = seq_len
    df["avg_click_prob"] = avg_prob
    df["seq_neglogcount"] = seq_neg
    df["seq_poslogcount"] = seq_pos

    print(f"âœ… seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: {df.shape[1]})")
    return df

# ===================================================
# 4. ì ìš©
# ===================================================
train_01 = add_seq_features(train_01)
train_02 = add_seq_features(train_02)
train_03 = add_seq_features(train_03)
test     = add_seq_features(test)
âœ… seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 134)
âœ… seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 134)
âœ… seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 134)
âœ… seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 133)

# =======================================================
# 1. í†µê³„ëŸ‰ & count map ê³„ì‚°
# =======================================================
full_train_df = pd.concat([train_01, train_02, train_03], ignore_index=True)

# 1) inventory_id ê¸°ì¤€ í†µê³„ëŸ‰
agg_targets = ['history_a_1','history_a_2','history_a_3', 'history_a_6','feat_d_4','l_feat_1','l_feat_2']

agg_stats = (
    full_train_df.groupby('inventory_id')[agg_targets]
    .agg(['mean','std'])
    .reset_index()
)
agg_stats.columns = ['inventory_id'] + [
    f'inventory_id_{col}_{stat}' for col, stat in agg_stats.columns[1:]
]

# 2) count encoding map
count_cols = ['age_group_inventory_id', 'inventory_id', 'inventory_id_hour']
count_maps = {col: full_train_df[col].value_counts().to_dict() for col in count_cols}

# ë©”ëª¨ë¦¬ ì •ë¦¬
del full_train_df
gc.collect()

# =======================================================
# 2. í•¨ìˆ˜ ì •ì˜
# =======================================================
def add_features(df: pd.DataFrame, name: str = "dataset") -> pd.DataFrame:
    """groupby í†µê³„ëŸ‰ + count encoding + ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    print(f"\nðŸš€ {name} ì²˜ë¦¬ ì‹œìž‘...")

    # 1) inventory_id í†µê³„ëŸ‰ merge
    df = df.merge(agg_stats, on='inventory_id', how='left')
    df.fillna(0, inplace=True)  # ìˆ«ìží˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬

    # 2) count encoding
    for col, cmap in count_maps.items():
        df[f"{col}_count"] = df[col].astype(str).map(cmap).fillna(0).astype(int)

    # 3) ë¬¸ìžì—´ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    obj_cols = df.select_dtypes(include='object').columns
    df[obj_cols] = df[obj_cols].fillna("missing").astype(str)

    print(f"âœ… {name}: seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: {df.shape[1]})")
    return df

# =======================================================
# 3. ì ìš©
# =======================================================
train_01 = add_features(train_01)
train_02 = add_features(train_02)
train_03 = add_features(train_03)
test     = add_features(test)
ðŸš€ dataset ì²˜ë¦¬ ì‹œìž‘...
âœ… dataset: seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 151)

ðŸš€ dataset ì²˜ë¦¬ ì‹œìž‘...
âœ… dataset: seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 151)

ðŸš€ dataset ì²˜ë¦¬ ì‹œìž‘...
âœ… dataset: seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 151)

ðŸš€ dataset ì²˜ë¦¬ ì‹œìž‘...
âœ… dataset: seq ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± ì™„ë£Œ (ì´ ì»¬ëŸ¼ ìˆ˜: 150)
Modeling

## íŠœë‹ì½”ë“œ

# -----------------------
# í´ëž˜ìŠ¤ ê· í˜• ê°€ì¤‘ì¹˜
# -----------------------
def make_class_balanced_weights(y_true):
    n_pos = (y_true == 1).sum()
    n_neg = (y_true == 0).sum()
    w_pos = 0.5 / (n_pos if n_pos > 0 else 1)
    w_neg = 0.5 / (n_neg if n_neg > 0 else 1)
    return np.where(y_true == 1, w_pos, w_neg)

# -----------------------
# ì „ì²˜ë¦¬
# -----------------------
BASE_EXCLUDE = {"clicked", "ID", "seq"}

def preprocess(df, exclude_features=None):
    exclude = BASE_EXCLUDE.copy()
    if exclude_features:
        exclude |= set(exclude_features)
    X = df.drop(columns=[c for c in exclude if c in df.columns], errors="ignore")

    for col in X.select_dtypes(include="object").columns:
        X[col] = X[col].astype("category").cat.codes.astype("int32")
    for col in X.select_dtypes(include=["int64"]).columns:
        X[col] = X[col].astype("int32")
    for col in X.select_dtypes(include=["float64"]).columns:
        X[col] = X[col].astype("float32")
    return X

# -----------------------
# Optuna íŠœë‹ í•¨ìˆ˜
# -----------------------
def tune_xgb_with_optuna(X, y, seed, n_trials=50):
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=seed
    )

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dval = xgb.DMatrix(X_val, label=y_val)

    scale_pos_weight = float((y_train == 0).sum() / max(1, (y_train == 1).sum()))
    sampler = TPESampler(seed=seed)
    study = optuna.create_study(direction="maximize", sampler=sampler)

    def objective(trial):
        params = {
            "objective": "binary:logistic",
            "eval_metric": "logloss",
            "tree_method": "gpu_hist",
            "scale_pos_weight": scale_pos_weight,
            "eta": trial.suggest_float("eta", 0.01, 0.2, log=True),
            "max_depth": trial.suggest_int("max_depth", 4, 12),
            "subsample": trial.suggest_float("subsample", 0.6, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
            "min_child_weight": trial.suggest_float("min_child_weight", 1.0, 200.0),
            "gamma": trial.suggest_float("gamma", 0.0, 5.0),
            "lambda": trial.suggest_float("lambda", 1e-8, 10.0, log=True),
            "alpha": trial.suggest_float("alpha", 1e-8, 10.0, log=True),
        }
        booster = xgb.train(
            params, dtrain,
            num_boost_round=1000,
            evals=[(dval, "valid")],
            early_stopping_rounds=30,
            verbose_eval=False
        )
        p_valid = booster.predict(dval, iteration_range=(0, booster.best_iteration + 1))
        ap = average_precision_score(y_val, p_valid)
        wll = log_loss(y_val, p_valid, sample_weight=make_class_balanced_weights(y_val), labels=[0, 1])
        final_score = 0.5 * ap + 0.5 * (1.0 / (1.0 + wll))
        return final_score

    study.optimize(objective, n_trials=n_trials)
    best_params = study.best_params
    best_params.update({
        "objective": "binary:logistic",
        "eval_metric": "logloss",
        "tree_method": "gpu_hist",
        "scale_pos_weight": float((y == 0).sum() / max(1, (y == 1).sum()))
    })
    return best_params

# -----------------------
# í•™ìŠµ+ì˜ˆì¸¡ í•¨ìˆ˜
# -----------------------
def train_and_predict(train_df, test_df, id_tag, seed, n_trials=50):
    print(f"\n=== START PIPELINE: {id_tag} | seed={seed} ===")

    random.seed(seed)
    np.random.seed(seed)

    y = train_df["clicked"].astype(int).values.ravel()
    X = preprocess(train_df)
    X_test = preprocess(test_df)
    test_ids = test_df["ID"].values if "ID" in test_df.columns else np.arange(len(test_df))

    # Optuna íƒìƒ‰
    print(f"[{id_tag}] Optuna tuning ...")
    best_params = tune_xgb_with_optuna(X, y, seed=seed, n_trials=n_trials)
    print(f"[{id_tag}] Best params:", best_params)

    # ìµœì¢… í•™ìŠµ
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dval = xgb.DMatrix(X_val, label=y_val)
    print(f"[{id_tag}] Training final model ...")
    model = xgb.train(
        best_params,
        dtrain,
        num_boost_round=1000,
        evals=[(dtrain, "train"), (dval, "valid")],
        early_stopping_rounds=50,
        verbose_eval=100
    )

    # ëª¨ë¸ ì €ìž¥
    model_path = os.path.join(DATA_PATH, f"model_{id_tag}.pkl")
    joblib.dump(model, model_path)
    print(f"[{id_tag}] Model saved -> {model_path} | best_iter={model.best_iteration}")

    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    dtest = xgb.DMatrix(X_test)
    preds = model.predict(dtest, iteration_range=(0, model.best_iteration + 1))
    sub = pd.DataFrame({"ID": test_ids, "clicked": preds})
    csv_path = os.path.join(DATA_PATH, f"submission_{id_tag}.csv")
    sub.to_csv(csv_path, index=False)
    print(f"[{id_tag}] Submission saved -> {csv_path} | shape={sub.shape}")
    print(f"=== END PIPELINE: {id_tag} ===\n")
    return model_path, csv_path

# -----------------------
# ì‹¤í–‰
# -----------------------
datasets = [
    {"df": train_01, "id": "train_01", "seed": 106},
    {"df": train_02, "id": "train_02", "seed": 1031},
    {"df": train_03, "id": "train_03", "seed": 42},
]

results = {}
for data in datasets:
    model_path, csv_path = train_and_predict(
        train_df=data["df"],
        test_df=test,
        id_tag=data["id"],
        seed=data["seed"],
        n_trials=50
    )
    results[data["id"]] = {"model": model_path, "submission": csv_path}

print("=== ALL DONE ===")
print(results)
=== START PIPELINE: train_01 | seed=106 ===
[train_01] Optuna tuning ...
[I 2025-10-16 17:22:40,716] A new study created in memory with name: no-name-9bc5a589-0b09-47a6-9e1e-7510869f3940
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:22:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:23:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:23:59,657] Trial 0 finished with value: 0.4562102885694287 and parameters: {'eta': 0.010259898367843918, 'max_depth': 12, 'subsample': 0.7798260137416737, 'colsample_bytree': 0.8440875086908464, 'min_child_weight': 170.55990367758548, 'gamma': 3.6940510569846796, 'lambda': 5.886868084847547, 'alpha': 0.5213830060758549}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:23:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:24:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:24:50,730] Trial 1 finished with value: 0.4302313124770113 and parameters: {'eta': 0.12969245549678007, 'max_depth': 11, 'subsample': 0.7409115664353482, 'colsample_bytree': 0.6848127138204806, 'min_child_weight': 156.30843112731282, 'gamma': 4.4970562619261045, 'lambda': 2.6894091077470376e-08, 'alpha': 1.725942108719862e-07}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:24:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:25:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:25:14,298] Trial 2 finished with value: 0.44719792178448253 and parameters: {'eta': 0.016959429932227252, 'max_depth': 4, 'subsample': 0.8041971336211003, 'colsample_bytree': 0.9068318574860014, 'min_child_weight': 97.4629651480209, 'gamma': 1.0480687973101976, 'lambda': 5.883584043745234e-05, 'alpha': 0.0011914622476351308}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:25:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:25:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:25:51,401] Trial 3 finished with value: 0.45592428048109324 and parameters: {'eta': 0.03231261271494027, 'max_depth': 8, 'subsample': 0.878459215150851, 'colsample_bytree': 0.9983267702729748, 'min_child_weight': 121.88666333135868, 'gamma': 4.098733632540553, 'lambda': 8.226366148429888e-07, 'alpha': 3.6547340824454687e-06}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:25:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:26:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:26:24,342] Trial 4 finished with value: 0.45533062310757944 and parameters: {'eta': 0.03747675161267263, 'max_depth': 7, 'subsample': 0.6383832477748829, 'colsample_bytree': 0.7067897088902373, 'min_child_weight': 43.665267217201894, 'gamma': 4.069685441830579, 'lambda': 2.233267736839201, 'alpha': 0.00016176136157935027}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:26:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:27:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:27:13,193] Trial 5 finished with value: 0.4555030044049946 and parameters: {'eta': 0.011145285606326615, 'max_depth': 9, 'subsample': 0.9287849811901827, 'colsample_bytree': 0.7103811088495633, 'min_child_weight': 105.47117465733899, 'gamma': 0.9063544068720936, 'lambda': 1.99794192228542e-05, 'alpha': 0.0004760472801518276}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:27:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:28:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:28:06,302] Trial 6 finished with value: 0.4484947777680297 and parameters: {'eta': 0.0596342753477238, 'max_depth': 11, 'subsample': 0.6157348881091559, 'colsample_bytree': 0.8540551487055713, 'min_child_weight': 177.01285539028473, 'gamma': 4.637748887270687, 'lambda': 0.0005908905379348481, 'alpha': 0.07054171037137091}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:28:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:28:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:28:25,162] Trial 7 finished with value: 0.45262654055829393 and parameters: {'eta': 0.149884234105829, 'max_depth': 4, 'subsample': 0.7787721318326417, 'colsample_bytree': 0.8150389438842341, 'min_child_weight': 46.49912103738026, 'gamma': 2.8434197986959564, 'lambda': 7.021484532875854e-07, 'alpha': 0.014390286101650792}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:28:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:28:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:29:00,025] Trial 8 finished with value: 0.45474204517138284 and parameters: {'eta': 0.018834075282988406, 'max_depth': 7, 'subsample': 0.8191345168056351, 'colsample_bytree': 0.7624435281173179, 'min_child_weight': 112.47926554398958, 'gamma': 1.2024449147371175, 'lambda': 4.0367260857513923e-07, 'alpha': 2.9527594648238074e-05}. Best is trial 0 with value: 0.4562102885694287.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:29:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:29:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:29:54,528] Trial 9 finished with value: 0.4562896576792572 and parameters: {'eta': 0.012860850648225347, 'max_depth': 10, 'subsample': 0.7205928773306879, 'colsample_bytree': 0.6689813209231922, 'min_child_weight': 156.88137281167516, 'gamma': 3.4472358980193736, 'lambda': 1.3434669340988894e-06, 'alpha': 3.159240699614752e-07}. Best is trial 9 with value: 0.4562896576792572.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:29:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:30:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:30:44,651] Trial 10 finished with value: 0.4364552099586296 and parameters: {'eta': 0.06094844934213889, 'max_depth': 10, 'subsample': 0.690392633260863, 'colsample_bytree': 0.6047636925891385, 'min_child_weight': 2.1583570068868028, 'gamma': 2.1623426949975606, 'lambda': 0.012562976128413294, 'alpha': 1.1378989315369847e-08}. Best is trial 9 with value: 0.4562896576792572.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:30:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:31:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:31:59,382] Trial 11 finished with value: 0.4560938998093671 and parameters: {'eta': 0.010970603786228673, 'max_depth': 12, 'subsample': 0.7128859085605112, 'colsample_bytree': 0.6030260304630786, 'min_child_weight': 198.2309641622693, 'gamma': 3.1928564345601718, 'lambda': 9.270351889877206, 'alpha': 9.571923887829545}. Best is trial 9 with value: 0.4562896576792572.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:31:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:33:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:33:10,350] Trial 12 finished with value: 0.45572601212814234 and parameters: {'eta': 0.020175490145032324, 'max_depth': 12, 'subsample': 0.8635938031764541, 'colsample_bytree': 0.9025209286652741, 'min_child_weight': 146.29558324057248, 'gamma': 3.5054201695119307, 'lambda': 0.08281803844523594, 'alpha': 9.284857578471543}. Best is trial 9 with value: 0.4562896576792572.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:33:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:34:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:34:05,291] Trial 13 finished with value: 0.4560132475045471 and parameters: {'eta': 0.011826065164376207, 'max_depth': 10, 'subsample': 0.6835061821562959, 'colsample_bytree': 0.7735134759561676, 'min_child_weight': 196.47270809710926, 'gamma': 2.053196659887272, 'lambda': 0.0014920048908479348, 'alpha': 0.2869737070613418}. Best is trial 9 with value: 0.4562896576792572.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:34:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:34:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:34:55,908] Trial 14 finished with value: 0.4563935066572962 and parameters: {'eta': 0.021164304418490716, 'max_depth': 10, 'subsample': 0.7568746048583755, 'colsample_bytree': 0.8442717714583533, 'min_child_weight': 155.62476718063922, 'gamma': 3.677496225121778, 'lambda': 1.1379175226546418e-05, 'alpha': 1.4155640179569129e-06}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:34:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:35:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:35:36,930] Trial 15 finished with value: 0.4563480140540876 and parameters: {'eta': 0.02826391295485515, 'max_depth': 9, 'subsample': 0.9742731394241305, 'colsample_bytree': 0.6667830691418137, 'min_child_weight': 136.10393509953528, 'gamma': 4.997205850366821, 'lambda': 1.5086290555149579e-05, 'alpha': 9.53260860794255e-07}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:35:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:36:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:36:14,963] Trial 16 finished with value: 0.45574488901631405 and parameters: {'eta': 0.023295109040162944, 'max_depth': 8, 'subsample': 0.979624253597503, 'colsample_bytree': 0.9533225997454129, 'min_child_weight': 135.41764960510395, 'gamma': 4.90429590313357, 'lambda': 1.7936669961219124e-05, 'alpha': 3.1187091922438305e-06}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:36:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:36:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:36:43,947] Trial 17 finished with value: 0.45447882283970914 and parameters: {'eta': 0.02859459999709175, 'max_depth': 6, 'subsample': 0.9577183666009653, 'colsample_bytree': 0.7689019075468262, 'min_child_weight': 73.08515731801897, 'gamma': 0.13088102755995346, 'lambda': 1.0307455103667087e-08, 'alpha': 1.2232688245212352e-08}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:36:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:37:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:37:24,098] Trial 18 finished with value: 0.45419899136792397 and parameters: {'eta': 0.04740288456318492, 'max_depth': 9, 'subsample': 0.901702826205503, 'colsample_bytree': 0.8873183284153165, 'min_child_weight': 89.97521789429985, 'gamma': 4.117278606091572, 'lambda': 0.00011208621032658076, 'alpha': 4.2404028608177887e-07}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:37:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:38:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:38:02,747] Trial 19 finished with value: 0.44800008369657607 and parameters: {'eta': 0.09659491289189436, 'max_depth': 9, 'subsample': 0.8481265103041272, 'colsample_bytree': 0.6467701821878749, 'min_child_weight': 133.2048056327723, 'gamma': 2.6576975890493024, 'lambda': 0.00569935361372619, 'alpha': 1.1194916752005692e-05}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:38:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:38:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:38:32,117] Trial 20 finished with value: 0.45409202785687214 and parameters: {'eta': 0.026279657254057395, 'max_depth': 6, 'subsample': 0.9961197802426028, 'colsample_bytree': 0.7367304146943343, 'min_child_weight': 175.83146048846172, 'gamma': 4.961942108303198, 'lambda': 4.876492643947519e-06, 'alpha': 9.358372812534611e-08}. Best is trial 14 with value: 0.4563935066572962.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:38:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:39:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:39:26,145] Trial 21 finished with value: 0.45658956095880854 and parameters: {'eta': 0.01365971862940199, 'max_depth': 10, 'subsample': 0.744825566102917, 'colsample_bytree': 0.6516498977231778, 'min_child_weight': 157.2717500812571, 'gamma': 3.1146849679078867, 'lambda': 3.075747139549897e-06, 'alpha': 1.2265896043197738e-06}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:39:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:40:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:40:27,695] Trial 22 finished with value: 0.4564102992709379 and parameters: {'eta': 0.016120791081447032, 'max_depth': 11, 'subsample': 0.7585514759153229, 'colsample_bytree': 0.6416533181147092, 'min_child_weight': 135.8106562542688, 'gamma': 2.9502873455120424, 'lambda': 7.190648650946365e-08, 'alpha': 1.0690879420927234e-06}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:40:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:41:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:41:29,426] Trial 23 finished with value: 0.4565299421617782 and parameters: {'eta': 0.014649690367467806, 'max_depth': 11, 'subsample': 0.7510820688841904, 'colsample_bytree': 0.6340484436541679, 'min_child_weight': 161.01057942695113, 'gamma': 2.994051849159808, 'lambda': 7.365994989101406e-08, 'alpha': 5.840586442962991e-05}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:41:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:42:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:42:29,643] Trial 24 finished with value: 0.4565340840882697 and parameters: {'eta': 0.015075385779272601, 'max_depth': 11, 'subsample': 0.6620945778792322, 'colsample_bytree': 0.6197074087865225, 'min_child_weight': 181.4118989292152, 'gamma': 2.184462584206324, 'lambda': 9.060387146033536e-08, 'alpha': 6.791194404145393e-05}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:42:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:43:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:43:29,820] Trial 25 finished with value: 0.45632882572865785 and parameters: {'eta': 0.0148331282855869, 'max_depth': 11, 'subsample': 0.6549648842221396, 'colsample_bytree': 0.6269436800120342, 'min_child_weight': 184.41593500916366, 'gamma': 2.196296428616876, 'lambda': 1.4294825929945476e-07, 'alpha': 8.658047212756717e-05}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:43:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:44:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:44:31,042] Trial 26 finished with value: 0.45626906037319365 and parameters: {'eta': 0.014335235768924225, 'max_depth': 11, 'subsample': 0.6006009819474238, 'colsample_bytree': 0.7100914229990338, 'min_child_weight': 165.24355404410935, 'gamma': 1.6504639131802163, 'lambda': 1.1384317409519486e-07, 'alpha': 0.0018866225892935004}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:44:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:45:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:45:30,224] Trial 27 finished with value: 0.45211844333687806 and parameters: {'eta': 0.040610079117959386, 'max_depth': 12, 'subsample': 0.6697687984345384, 'colsample_bytree': 0.6298733745820615, 'min_child_weight': 187.09364657843008, 'gamma': 2.4271191304132564, 'lambda': 1.5943311319507593e-08, 'alpha': 3.538562070529592e-05}. Best is trial 21 with value: 0.45658956095880854.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:45:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:46:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:46:22,335] Trial 28 finished with value: 0.45660300290920863 and parameters: {'eta': 0.016544777993753507, 'max_depth': 10, 'subsample': 0.7273356668515201, 'colsample_bytree': 0.6777314606289676, 'min_child_weight': 148.81244596583159, 'gamma': 1.6631436038487226, 'lambda': 1.7441253083422276e-06, 'alpha': 0.003320194332128831}. Best is trial 28 with value: 0.45660300290920863.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:46:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:47:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:47:20,501] Trial 29 finished with value: 0.4560108471094818 and parameters: {'eta': 0.010269925686884777, 'max_depth': 10, 'subsample': 0.7116594707577822, 'colsample_bytree': 0.6825849424928003, 'min_child_weight': 119.34076006260776, 'gamma': 1.6752434088934898, 'lambda': 1.1738780043278692e-06, 'alpha': 0.023273762725940984}. Best is trial 28 with value: 0.45660300290920863.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:47:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:48:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:48:24,750] Trial 30 finished with value: 0.4557367757994886 and parameters: {'eta': 0.022758778127682098, 'max_depth': 12, 'subsample': 0.6485158902590165, 'colsample_bytree': 0.7244268648363273, 'min_child_weight': 170.25898483013808, 'gamma': 1.6415605376077822, 'lambda': 2.994164319749885e-06, 'alpha': 0.006053434647877599}. Best is trial 28 with value: 0.45660300290920863.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:48:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:49:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:49:27,872] Trial 31 finished with value: 0.45650852600049474 and parameters: {'eta': 0.01372180910801899, 'max_depth': 11, 'subsample': 0.7812282805791129, 'colsample_bytree': 0.6582911783700536, 'min_child_weight': 150.71056583832842, 'gamma': 3.0616891725157593, 'lambda': 1.6403473448788242e-07, 'alpha': 0.0003756341071690183}. Best is trial 28 with value: 0.45660300290920863.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:49:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:50:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:50:19,442] Trial 32 finished with value: 0.456716173754968 and parameters: {'eta': 0.017157602606714745, 'max_depth': 10, 'subsample': 0.7374546934136761, 'colsample_bytree': 0.62021628056724, 'min_child_weight': 166.4578793078511, 'gamma': 2.5131209294713943, 'lambda': 6.22581603777314e-08, 'alpha': 1.2152318879703765e-05}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:50:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:51:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:51:04,173] Trial 33 finished with value: 0.456127621377427 and parameters: {'eta': 0.017704087782727685, 'max_depth': 9, 'subsample': 0.7250189314563061, 'colsample_bytree': 0.602015328584051, 'min_child_weight': 185.31076668841425, 'gamma': 2.555878056250808, 'lambda': 5.019284655678274e-08, 'alpha': 6.019497326343485e-06}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:51:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:51:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:51:55,542] Trial 34 finished with value: 0.45658354141922763 and parameters: {'eta': 0.018227736438459853, 'max_depth': 10, 'subsample': 0.6933154684305698, 'colsample_bytree': 0.6763841679715483, 'min_child_weight': 167.4266055719665, 'gamma': 1.899012531301866, 'lambda': 2.7283738062690245e-07, 'alpha': 0.0016681818593822166}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:51:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:52:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:52:42,564] Trial 35 finished with value: 0.4557480945140176 and parameters: {'eta': 0.03298096540552447, 'max_depth': 10, 'subsample': 0.8240009571300723, 'colsample_bytree': 0.6895442084929118, 'min_child_weight': 142.1715587778924, 'gamma': 1.3899418868874143, 'lambda': 9.880194784162077e-05, 'alpha': 0.0017614018421378411}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:52:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:53:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:53:22,771] Trial 36 finished with value: 0.4556826095141927 and parameters: {'eta': 0.01731957147324854, 'max_depth': 8, 'subsample': 0.6979287579396897, 'colsample_bytree': 0.7433964343449241, 'min_child_weight': 123.39839902444916, 'gamma': 0.6539512335470998, 'lambda': 2.990429176452417e-07, 'alpha': 9.893348167556824e-08}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:53:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:54:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:54:05,938] Trial 37 finished with value: 0.45625837643906386 and parameters: {'eta': 0.023857897706141877, 'max_depth': 9, 'subsample': 0.7356592416616525, 'colsample_bytree': 0.6897016978381794, 'min_child_weight': 167.2741430372501, 'gamma': 1.8684414621489673, 'lambda': 1.918918076460198e-06, 'alpha': 0.000536455219059707}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:54:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:54:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:54:40,519] Trial 38 finished with value: 0.4511830095469803 and parameters: {'eta': 0.09869805319022473, 'max_depth': 8, 'subsample': 0.7897989001165924, 'colsample_bytree': 0.6734953755250112, 'min_child_weight': 147.86548647678262, 'gamma': 0.7222479884619485, 'lambda': 3.897596630799797e-06, 'alpha': 0.003282272048408325}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:54:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:55:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:55:32,512] Trial 39 finished with value: 0.4560877985744555 and parameters: {'eta': 0.01905360487138656, 'max_depth': 10, 'subsample': 0.6319713113695831, 'colsample_bytree': 0.8131748730210322, 'min_child_weight': 126.50788160233154, 'gamma': 1.2567143378926928, 'lambda': 2.9163491552087263e-08, 'alpha': 0.08053501445906591}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:55:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:56:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:56:09,543] Trial 40 finished with value: 0.4534365173926886 and parameters: {'eta': 0.012086458761604144, 'max_depth': 7, 'subsample': 0.7721222877463844, 'colsample_bytree': 0.6534342947210917, 'min_child_weight': 102.4307309751038, 'gamma': 3.280459097044611, 'lambda': 4.33653534048954e-05, 'alpha': 0.011109841591286}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:56:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:57:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:57:09,266] Trial 41 finished with value: 0.4566075653703432 and parameters: {'eta': 0.016415953056781497, 'max_depth': 11, 'subsample': 0.6713980720641052, 'colsample_bytree': 0.6255736714745089, 'min_child_weight': 179.53533071796903, 'gamma': 2.351549999447204, 'lambda': 4.2440307231615647e-07, 'alpha': 0.0002064007677539705}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:57:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:58:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:58:01,071] Trial 42 finished with value: 0.45628644786602135 and parameters: {'eta': 0.017129328652387643, 'max_depth': 10, 'subsample': 0.6783538501950741, 'colsample_bytree': 0.7020067551135847, 'min_child_weight': 172.80993905936853, 'gamma': 2.374935698926821, 'lambda': 4.417934103330047e-07, 'alpha': 1.2262017655854633e-05}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:58:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:59:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 17:59:03,135] Trial 43 finished with value: 0.45663088135340396 and parameters: {'eta': 0.01310995225848454, 'max_depth': 11, 'subsample': 0.6976899216747091, 'colsample_bytree': 0.6184211076096275, 'min_child_weight': 192.61292897933913, 'gamma': 2.6575945757149215, 'lambda': 6.092952963675466e-07, 'alpha': 0.0008873271897631482}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:59:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:00:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:00:13,539] Trial 44 finished with value: 0.45666404832968793 and parameters: {'eta': 0.01276980072473076, 'max_depth': 12, 'subsample': 0.7358505005192798, 'colsample_bytree': 0.6173961170472259, 'min_child_weight': 192.0415764183546, 'gamma': 2.690225724801362, 'lambda': 8.515355210125584e-07, 'alpha': 0.00019431657063687197}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:00:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:01:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:01:31,310] Trial 45 finished with value: 0.4565122139280965 and parameters: {'eta': 0.010305410552373969, 'max_depth': 12, 'subsample': 0.8038487129319972, 'colsample_bytree': 0.6185232093289599, 'min_child_weight': 192.74884539829333, 'gamma': 2.755995061297585, 'lambda': 7.517574543396409e-07, 'alpha': 0.00018442490128331516}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:01:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:02:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:02:42,314] Trial 46 finished with value: 0.456414797265305 and parameters: {'eta': 0.01222116999558441, 'max_depth': 12, 'subsample': 0.7105267726102722, 'colsample_bytree': 0.6002322128329182, 'min_child_weight': 190.69649570615164, 'gamma': 2.7727296534582693, 'lambda': 1.7028383708560793, 'alpha': 0.0007593810247521802}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:02:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:03:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:03:39,324] Trial 47 finished with value: 0.45636918772015506 and parameters: {'eta': 0.020759465170512182, 'max_depth': 11, 'subsample': 0.6297960862909698, 'colsample_bytree': 0.618669608432682, 'min_child_weight': 199.75447765454646, 'gamma': 2.3893105609812233, 'lambda': 7.61907816107053e-07, 'alpha': 0.05696434618609549}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:03:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:04:51,181] Trial 48 finished with value: 0.4565650695650848 and parameters: {'eta': 0.01218608841454938, 'max_depth': 12, 'subsample': 0.7363718547563315, 'colsample_bytree': 0.6365361079064057, 'min_child_weight': 180.91514536493193, 'gamma': 3.3932012564583296, 'lambda': 8.984866478909785e-06, 'alpha': 0.00018117030914318555}. Best is trial 32 with value: 0.456716173754968.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:05:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:05:45,257] Trial 49 finished with value: 0.4555094180490149 and parameters: {'eta': 0.03243467888682409, 'max_depth': 11, 'subsample': 0.767650347786967, 'colsample_bytree': 0.615505127842574, 'min_child_weight': 176.4471724458113, 'gamma': 1.9847063345525497, 'lambda': 2.201819244442442e-08, 'alpha': 2.4321753329323584e-05}. Best is trial 32 with value: 0.456716173754968.
[train_01] Best params: {'eta': 0.017157602606714745, 'max_depth': 10, 'subsample': 0.7374546934136761, 'colsample_bytree': 0.62021628056724, 'min_child_weight': 166.4578793078511, 'gamma': 2.5131209294713943, 'lambda': 6.22581603777314e-08, 'alpha': 1.2152318879703765e-05, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0}
[train_01] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:05:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69052	valid-logloss:0.69056
[100]	train-logloss:0.59416	valid-logloss:0.59730
[200]	train-logloss:0.57572	valid-logloss:0.58169
[300]	train-logloss:0.56673	valid-logloss:0.57485
[400]	train-logloss:0.56077	valid-logloss:0.57051
[500]	train-logloss:0.55571	valid-logloss:0.56700
[600]	train-logloss:0.55156	valid-logloss:0.56423
[700]	train-logloss:0.54734	valid-logloss:0.56140
[800]	train-logloss:0.54341	valid-logloss:0.55879
[900]	train-logloss:0.53966	valid-logloss:0.55636
[999]	train-logloss:0.53625	valid-logloss:0.55416
[train_01] Model saved -> /content/drive/MyDrive/toss/model_train_01.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [18:06:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_01] Submission saved -> /content/drive/MyDrive/toss/submission_train_01.csv | shape=(1527298, 2)
=== END PIPELINE: train_01 ===


=== START PIPELINE: train_02 | seed=1031 ===
[train_02] Optuna tuning ...
[I 2025-10-16 18:07:05,554] A new study created in memory with name: no-name-c13eef27-90a5-4f79-b5ef-d78004a2f0be
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:07:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:07:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:07:40,400] Trial 0 finished with value: 0.4495661410989295 and parameters: {'eta': 0.010030542235435747, 'max_depth': 6, 'subsample': 0.7299275357796907, 'colsample_bytree': 0.7672919056877435, 'min_child_weight': 154.42315013332836, 'gamma': 4.788695606033571, 'lambda': 5.83864310031862e-07, 'alpha': 0.0010984897811838177}. Best is trial 0 with value: 0.4495661410989295.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:07:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:08:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:08:29,432] Trial 1 finished with value: 0.41718198491540837 and parameters: {'eta': 0.11978434297771987, 'max_depth': 10, 'subsample': 0.8028360964022752, 'colsample_bytree': 0.9033177780841783, 'min_child_weight': 17.555385408203744, 'gamma': 3.2365936437527756, 'lambda': 3.0923631972991695e-05, 'alpha': 0.1762792686327148}. Best is trial 0 with value: 0.4495661410989295.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:08:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:08:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:08:53,389] Trial 2 finished with value: 0.45316621614485697 and parameters: {'eta': 0.10906556872094157, 'max_depth': 5, 'subsample': 0.9142579862520679, 'colsample_bytree': 0.6779087429950191, 'min_child_weight': 95.29129046812108, 'gamma': 1.0021838184592675, 'lambda': 3.2364618499733116e-05, 'alpha': 0.0333939381887896}. Best is trial 2 with value: 0.45316621614485697.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:08:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:09:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:09:48,038] Trial 3 finished with value: 0.4538796088940006 and parameters: {'eta': 0.03100179485528144, 'max_depth': 11, 'subsample': 0.8802289372261811, 'colsample_bytree': 0.9134708800751964, 'min_child_weight': 163.6373496504015, 'gamma': 0.28769206765301814, 'lambda': 0.01918937732409002, 'alpha': 0.001561062520557587}. Best is trial 3 with value: 0.4538796088940006.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:09:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:10:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:10:37,094] Trial 4 finished with value: 0.45509047760433397 and parameters: {'eta': 0.024571259525956374, 'max_depth': 10, 'subsample': 0.8315487993463885, 'colsample_bytree': 0.8126812809938139, 'min_child_weight': 168.13102409615647, 'gamma': 2.8223364779872884, 'lambda': 0.0014542333759947426, 'alpha': 2.046474163548632e-08}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:10:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:12:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:12:10,085] Trial 5 finished with value: 0.4522520969070938 and parameters: {'eta': 0.01123782546938741, 'max_depth': 12, 'subsample': 0.7506099162864155, 'colsample_bytree': 0.6449079499177813, 'min_child_weight': 13.35277193012827, 'gamma': 2.212607475697542, 'lambda': 1.1171583774354873e-05, 'alpha': 6.375537722733453e-06}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:12:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:12:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:12:40,556] Trial 6 finished with value: 0.4527421695406355 and parameters: {'eta': 0.0212349664801717, 'max_depth': 6, 'subsample': 0.8410473915489125, 'colsample_bytree': 0.8635106403742614, 'min_child_weight': 12.231147385881542, 'gamma': 3.122276229707814, 'lambda': 3.117610840413139e-08, 'alpha': 0.00027136940062626506}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:12:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:13:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:13:10,113] Trial 7 finished with value: 0.45361445339200757 and parameters: {'eta': 0.033340968057874884, 'max_depth': 6, 'subsample': 0.6939325773213975, 'colsample_bytree': 0.8608726342311077, 'min_child_weight': 44.099927987267975, 'gamma': 4.481866923689191, 'lambda': 4.511472073640617e-05, 'alpha': 7.241851531057947e-05}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:13:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:13:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:13:32,050] Trial 8 finished with value: 0.45196462075514343 and parameters: {'eta': 0.14523749157796018, 'max_depth': 4, 'subsample': 0.7095763290451396, 'colsample_bytree': 0.7234571275040663, 'min_child_weight': 152.94053003246003, 'gamma': 4.147653481114247, 'lambda': 0.0008265852100429614, 'alpha': 0.0002509792359582836}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:13:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:14:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:14:26,429] Trial 9 finished with value: 0.4288117794862897 and parameters: {'eta': 0.1304901406592014, 'max_depth': 12, 'subsample': 0.9152339953918208, 'colsample_bytree': 0.7266000305033437, 'min_child_weight': 167.57378681213171, 'gamma': 2.6870856451308454, 'lambda': 0.0029744565415165546, 'alpha': 0.007092716235214402}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:14:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:15:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:15:07,893] Trial 10 finished with value: 0.45091347357187817 and parameters: {'eta': 0.05892531756209202, 'max_depth': 9, 'subsample': 0.6057200544649092, 'colsample_bytree': 0.9993261210833342, 'min_child_weight': 196.16653399334535, 'gamma': 1.7105517604592764, 'lambda': 4.962382210486622, 'alpha': 1.776807912644946e-08}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:15:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:15:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:15:57,761] Trial 11 finished with value: 0.4544496960579888 and parameters: {'eta': 0.02163422666134718, 'max_depth': 10, 'subsample': 0.9903026531171293, 'colsample_bytree': 0.9618092454835587, 'min_child_weight': 102.71597166911329, 'gamma': 0.6465206751475088, 'lambda': 0.11275864027594908, 'alpha': 2.2136582750566602e-08}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:15:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:16:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:16:37,345] Trial 12 finished with value: 0.4542586418959372 and parameters: {'eta': 0.01826149564962308, 'max_depth': 8, 'subsample': 0.9662932103245664, 'colsample_bytree': 0.9881703606648623, 'min_child_weight': 102.5609945925491, 'gamma': 1.3768204960061095, 'lambda': 0.298208345971041, 'alpha': 1.1777542623970856e-08}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:16:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:17:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:17:19,968] Trial 13 finished with value: 0.4505926311939611 and parameters: {'eta': 0.057350053549259844, 'max_depth': 10, 'subsample': 0.9919625003376639, 'colsample_bytree': 0.8079971793568743, 'min_child_weight': 110.67627553810019, 'gamma': 0.5036771753813132, 'lambda': 0.06280012788618082, 'alpha': 1.0576798001670733e-06}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:17:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:18:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:18:00,610] Trial 14 finished with value: 0.4543519376077998 and parameters: {'eta': 0.017484986284738675, 'max_depth': 8, 'subsample': 0.8245479660976048, 'colsample_bytree': 0.9490380450947113, 'min_child_weight': 69.20448421614599, 'gamma': 3.590245291918318, 'lambda': 2.87770444629303, 'alpha': 3.649353198671547e-07}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:18:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:18:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:18:47,526] Trial 15 finished with value: 0.4541722227000816 and parameters: {'eta': 0.031030272609689217, 'max_depth': 10, 'subsample': 0.9461013216841414, 'colsample_bytree': 0.8242978179644305, 'min_child_weight': 127.82929247993216, 'gamma': 2.129070467640303, 'lambda': 0.008228150796032143, 'alpha': 1.860491005461211e-07}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:18:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:19:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:19:29,084] Trial 16 finished with value: 0.45343587465818086 and parameters: {'eta': 0.048297553725014125, 'max_depth': 9, 'subsample': 0.6475592158813495, 'colsample_bytree': 0.7573103008483755, 'min_child_weight': 197.92563608654436, 'gamma': 0.004704754225469898, 'lambda': 0.22452634718039013, 'alpha': 1.4775517223487311}. Best is trial 4 with value: 0.45509047760433397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:19:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:20:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:20:34,772] Trial 17 finished with value: 0.45530882825999375 and parameters: {'eta': 0.014308474626963049, 'max_depth': 11, 'subsample': 0.8668803439377712, 'colsample_bytree': 0.6226340593881317, 'min_child_weight': 74.17509559676546, 'gamma': 0.7893381681342838, 'lambda': 0.0005641665274894962, 'alpha': 4.180162588088501e-06}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:20:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:21:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:21:40,915] Trial 18 finished with value: 0.4551110197664717 and parameters: {'eta': 0.013992908490286135, 'max_depth': 11, 'subsample': 0.8621376008892495, 'colsample_bytree': 0.6178410329544236, 'min_child_weight': 67.16933042857977, 'gamma': 1.6165253231575498, 'lambda': 0.00024487898300414994, 'alpha': 5.647662316986834e-06}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:21:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:23:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:23:01,638] Trial 19 finished with value: 0.4546722556362387 and parameters: {'eta': 0.013740308646691781, 'max_depth': 12, 'subsample': 0.7683710382377407, 'colsample_bytree': 0.6066640446484697, 'min_child_weight': 66.0947006871738, 'gamma': 1.4322199793741466, 'lambda': 0.00021155543610811044, 'alpha': 9.185728148318753e-06}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:23:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:24:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:24:07,156] Trial 20 finished with value: 0.45506682901670875 and parameters: {'eta': 0.014709696845483618, 'max_depth': 11, 'subsample': 0.8749193351965495, 'colsample_bytree': 0.6277303689836409, 'min_child_weight': 67.79842207216211, 'gamma': 0.9586266733085517, 'lambda': 1.9792278569799687e-06, 'alpha': 1.993067371154693e-05}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:24:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:25:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:25:08,519] Trial 21 finished with value: 0.45294539132726297 and parameters: {'eta': 0.024717962045853567, 'max_depth': 11, 'subsample': 0.8491515534804395, 'colsample_bytree': 0.6731809384456452, 'min_child_weight': 40.47598432392211, 'gamma': 1.9155360698880097, 'lambda': 0.0005903841021404989, 'alpha': 1.283668596077131e-06}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:25:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:25:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:25:56,262] Trial 22 finished with value: 0.45481358136292294 and parameters: {'eta': 0.01336555721680962, 'max_depth': 9, 'subsample': 0.8000316331414475, 'colsample_bytree': 0.689805235334988, 'min_child_weight': 80.81923591843089, 'gamma': 2.6277919834786485, 'lambda': 0.00028678620715424805, 'alpha': 1.1222091789245751e-07}. Best is trial 17 with value: 0.45530882825999375.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:25:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:26:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:26:57,122] Trial 23 finished with value: 0.45535639109068304 and parameters: {'eta': 0.0165524536383825, 'max_depth': 11, 'subsample': 0.8835794548721979, 'colsample_bytree': 0.6062447406980779, 'min_child_weight': 128.31152311116554, 'gamma': 1.2319429731089833, 'lambda': 0.003064375611051981, 'alpha': 1.488958799603441e-06}. Best is trial 23 with value: 0.45535639109068304.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:26:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:27:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:27:58,177] Trial 24 finished with value: 0.4553994013868848 and parameters: {'eta': 0.01661848264839599, 'max_depth': 11, 'subsample': 0.8949436273822405, 'colsample_bytree': 0.602295762707455, 'min_child_weight': 128.4919415919919, 'gamma': 1.0314846185170998, 'lambda': 0.00928317111311405, 'alpha': 3.5549264575741018e-06}. Best is trial 24 with value: 0.4553994013868848.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:27:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:28:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:28:55,422] Trial 25 finished with value: 0.43834543217216576 and parameters: {'eta': 0.08840713566823792, 'max_depth': 12, 'subsample': 0.9090333007838637, 'colsample_bytree': 0.6443333543461074, 'min_child_weight': 129.47115397163523, 'gamma': 1.038183137904034, 'lambda': 0.012507769016860088, 'alpha': 4.523727742027344e-05}. Best is trial 24 with value: 0.4553994013868848.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:28:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:29:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:29:27,328] Trial 26 finished with value: 0.45456505877066034 and parameters: {'eta': 0.04050881320539208, 'max_depth': 7, 'subsample': 0.8905084687385147, 'colsample_bytree': 0.6049973886603165, 'min_child_weight': 127.49682368045974, 'gamma': 0.6989111044088094, 'lambda': 0.7835709926809654, 'alpha': 1.8656463098472082e-06}. Best is trial 24 with value: 0.4553994013868848.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:29:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:30:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:30:27,909] Trial 27 finished with value: 0.45545323059904363 and parameters: {'eta': 0.016271712241103357, 'max_depth': 11, 'subsample': 0.9451140044391817, 'colsample_bytree': 0.707359562778431, 'min_child_weight': 140.26892309314096, 'gamma': 0.14342296795415266, 'lambda': 0.004349553563477939, 'alpha': 1.0213163630339229e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:30:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:31:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:31:04,029] Trial 28 finished with value: 0.4313991210689356 and parameters: {'eta': 0.19279990158969404, 'max_depth': 9, 'subsample': 0.9451128353798689, 'colsample_bytree': 0.6955641452614385, 'min_child_weight': 142.02980748046033, 'gamma': 0.04383758581119221, 'lambda': 0.03893327593755551, 'alpha': 9.380526972268419e-08}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:31:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:32:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:32:26,009] Trial 29 finished with value: 0.4550856390839485 and parameters: {'eta': 0.010089704429380028, 'max_depth': 12, 'subsample': 0.9432944277413194, 'colsample_bytree': 0.7491789839087749, 'min_child_weight': 144.79264490909037, 'gamma': 1.3261255290021825, 'lambda': 0.005670561062467918, 'alpha': 3.8966246751009643e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:32:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:33:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:33:24,048] Trial 30 finished with value: 0.45511731455764365 and parameters: {'eta': 0.017665669767684612, 'max_depth': 11, 'subsample': 0.9630505755878225, 'colsample_bytree': 0.7844928233240713, 'min_child_weight': 184.347569240635, 'gamma': 0.3592042639538059, 'lambda': 1.4158310147831104e-07, 'alpha': 7.427595178462329e-08}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:33:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:34:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:34:30,678] Trial 31 finished with value: 0.4551889653470785 and parameters: {'eta': 0.011582510627087787, 'max_depth': 11, 'subsample': 0.9035896944764547, 'colsample_bytree': 0.6525304722686756, 'min_child_weight': 120.31044447726596, 'gamma': 0.7338726938462983, 'lambda': 0.0034296340017270274, 'alpha': 7.667357106407641e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:34:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:35:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:35:23,618] Trial 32 finished with value: 0.4553083530709487 and parameters: {'eta': 0.0167390610706323, 'max_depth': 10, 'subsample': 0.8705412971083181, 'colsample_bytree': 0.6579040379982729, 'min_child_weight': 86.35288136739274, 'gamma': 1.0885793740718328, 'lambda': 9.83384081732415e-05, 'alpha': 2.614014103605529e-06}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:35:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:36:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:36:21,955] Trial 33 finished with value: 0.4550223928278604 and parameters: {'eta': 0.021549119998173098, 'max_depth': 11, 'subsample': 0.9242061577324562, 'colsample_bytree': 0.7113477415364252, 'min_child_weight': 114.72908137420578, 'gamma': 0.2866320115513792, 'lambda': 4.855273922721418e-06, 'alpha': 7.12157312878585e-05}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:36:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:37:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:37:28,227] Trial 34 finished with value: 0.45383838624660755 and parameters: {'eta': 0.02571721682195906, 'max_depth': 12, 'subsample': 0.8148318957722483, 'colsample_bytree': 0.6337729653955485, 'min_child_weight': 139.03056014232294, 'gamma': 1.1802883900815924, 'lambda': 0.0018673178641098853, 'alpha': 1.443804114813968e-05}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:37:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:38:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:38:25,212] Trial 35 finished with value: 0.4550871722505506 and parameters: {'eta': 0.011625471974110981, 'max_depth': 10, 'subsample': 0.8845765258369349, 'colsample_bytree': 0.6006830986820161, 'min_child_weight': 90.36836836601404, 'gamma': 0.798252986212242, 'lambda': 0.02254863185771642, 'alpha': 3.875014191956781e-06}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:38:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:39:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:39:20,638] Trial 36 finished with value: 0.45423753142078926 and parameters: {'eta': 0.027661343385778747, 'max_depth': 11, 'subsample': 0.7777270110700819, 'colsample_bytree': 0.6724686800936744, 'min_child_weight': 154.71269453156893, 'gamma': 0.276914705921509, 'lambda': 0.0009078073558773427, 'alpha': 3.774424554848496e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:39:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:40:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:40:06,149] Trial 37 finished with value: 0.45500458806091915 and parameters: {'eta': 0.015588834443469472, 'max_depth': 9, 'subsample': 0.8481385198252349, 'colsample_bytree': 0.6341924110127453, 'min_child_weight': 178.80293401764544, 'gamma': 2.370743857157936, 'lambda': 3.957762819904563e-05, 'alpha': 0.0006009457521563494}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:40:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:41:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:41:38,734] Trial 38 finished with value: 0.4540362044665194 and parameters: {'eta': 0.010085565557456058, 'max_depth': 12, 'subsample': 0.9360485713923601, 'colsample_bytree': 0.6623099090363208, 'min_child_weight': 33.40347788008499, 'gamma': 1.846005465725153, 'lambda': 1.4412789662646936e-05, 'alpha': 3.7261972467016814e-08}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:41:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:42:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:42:13,087] Trial 39 finished with value: 0.45376843586073967 and parameters: {'eta': 0.019595034468783353, 'max_depth': 7, 'subsample': 0.8930224941990533, 'colsample_bytree': 0.7118057473151624, 'min_child_weight': 156.60713895095358, 'gamma': 4.942702262059415, 'lambda': 0.012601913131928379, 'alpha': 2.504586838325839e-05}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:42:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:42:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:42:59,899] Trial 40 finished with value: 0.45301500009788276 and parameters: {'eta': 0.03532764234827479, 'max_depth': 10, 'subsample': 0.9662315302460422, 'colsample_bytree': 0.6278274478338857, 'min_child_weight': 53.70946098186488, 'gamma': 0.5001466556260373, 'lambda': 0.003602133970634681, 'alpha': 0.002408828761926542}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:42:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:43:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:43:53,312] Trial 41 finished with value: 0.4553330150344981 and parameters: {'eta': 0.01616689875304652, 'max_depth': 10, 'subsample': 0.8676053658982037, 'colsample_bytree': 0.6546974513065269, 'min_child_weight': 86.70283669117829, 'gamma': 1.0001612380241356, 'lambda': 8.71899623239613e-05, 'alpha': 2.6095516838213646e-06}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:43:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:44:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:45:00,744] Trial 42 finished with value: 0.45514636954323623 and parameters: {'eta': 0.012483178822510677, 'max_depth': 11, 'subsample': 0.8638446358005821, 'colsample_bytree': 0.6894462757022994, 'min_child_weight': 77.71552486493886, 'gamma': 0.9845313394205814, 'lambda': 8.880258585026368e-05, 'alpha': 0.00016117336052516056}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:45:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:46:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:46:15,400] Trial 43 finished with value: 0.45505111365386086 and parameters: {'eta': 0.015448026990445424, 'max_depth': 12, 'subsample': 0.9251443569025769, 'colsample_bytree': 0.619037717124344, 'min_child_weight': 101.55170940083056, 'gamma': 1.564221343097526, 'lambda': 0.0016929575068574325, 'alpha': 6.077308694161331e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:46:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:47:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:47:05,720] Trial 44 finished with value: 0.45517167372889267 and parameters: {'eta': 0.020852918611915062, 'max_depth': 10, 'subsample': 0.8491205684533891, 'colsample_bytree': 0.645210333951548, 'min_child_weight': 117.76374988491, 'gamma': 1.241355834602686, 'lambda': 0.0009724162812066455, 'alpha': 2.868170671488902e-06}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:47:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:48:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:48:03,282] Trial 45 finished with value: 0.4548433392731003 and parameters: {'eta': 0.02273098929708283, 'max_depth': 11, 'subsample': 0.8307473096516392, 'colsample_bytree': 0.6666023470374542, 'min_child_weight': 135.89227887708148, 'gamma': 0.8542041887183384, 'lambda': 8.590095907745096e-05, 'alpha': 4.547026359594394e-08}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:48:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:48:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:48:41,449] Trial 46 finished with value: 0.45489562640350156 and parameters: {'eta': 0.02754070113082984, 'max_depth': 8, 'subsample': 0.9013537858524527, 'colsample_bytree': 0.7403392508630467, 'min_child_weight': 108.99019566557241, 'gamma': 0.550871611992451, 'lambda': 1.787058764122839e-05, 'alpha': 8.861263951190434}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:48:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:49:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:49:05,371] Trial 47 finished with value: 0.4459600076992012 and parameters: {'eta': 0.01616020505839071, 'max_depth': 4, 'subsample': 0.9751126321073149, 'colsample_bytree': 0.6148254479968241, 'min_child_weight': 93.86270098514123, 'gamma': 2.9338307258962804, 'lambda': 0.00043055427049325896, 'alpha': 0.03369119486532643}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:49:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:49:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:49:56,187] Trial 48 finished with value: 0.4551302919028771 and parameters: {'eta': 0.018888732966179444, 'max_depth': 10, 'subsample': 0.7829850778579606, 'colsample_bytree': 0.6491438514878235, 'min_child_weight': 148.13377943172793, 'gamma': 0.18095979325184908, 'lambda': 0.04926740568503394, 'alpha': 1.5078612827649045e-07}. Best is trial 27 with value: 0.45545323059904363.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:49:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:50:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:50:53,209] Trial 49 finished with value: 0.45502498291927573 and parameters: {'eta': 0.012642670902468588, 'max_depth': 10, 'subsample': 0.9179047287052792, 'colsample_bytree': 0.7781747977386297, 'min_child_weight': 57.81571652446574, 'gamma': 1.9662092678373049, 'lambda': 9.75750977411977e-07, 'alpha': 6.996801319455741e-06}. Best is trial 27 with value: 0.45545323059904363.
[train_02] Best params: {'eta': 0.016271712241103357, 'max_depth': 11, 'subsample': 0.9451140044391817, 'colsample_bytree': 0.707359562778431, 'min_child_weight': 140.26892309314096, 'gamma': 0.14342296795415266, 'lambda': 0.004349553563477939, 'alpha': 1.0213163630339229e-07, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0}
[train_02] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:50:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69049	valid-logloss:0.69057
[100]	train-logloss:0.58774	valid-logloss:0.59382
[200]	train-logloss:0.56435	valid-logloss:0.57525
[300]	train-logloss:0.55234	valid-logloss:0.56652
[400]	train-logloss:0.54517	valid-logloss:0.56155
[500]	train-logloss:0.53908	valid-logloss:0.55741
[600]	train-logloss:0.53375	valid-logloss:0.55386
[700]	train-logloss:0.52875	valid-logloss:0.55060
[800]	train-logloss:0.52412	valid-logloss:0.54757
[900]	train-logloss:0.51946	valid-logloss:0.54451
[999]	train-logloss:0.51507	valid-logloss:0.54165
[train_02] Model saved -> /content/drive/MyDrive/toss/model_train_02.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [18:52:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_02] Submission saved -> /content/drive/MyDrive/toss/submission_train_02.csv | shape=(1527298, 2)
=== END PIPELINE: train_02 ===


=== START PIPELINE: train_03 | seed=42 ===
[train_03] Optuna tuning ...
[I 2025-10-16 18:52:21,638] A new study created in memory with name: no-name-b85e08f6-bcc2-4ad4-88bd-bac7bb9981c6
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:52:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:53:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:53:38,296] Trial 0 finished with value: 0.44681722167419224 and parameters: {'eta': 0.030710573677773714, 'max_depth': 12, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'min_child_weight': 32.04770944804487, 'gamma': 0.7799726016810132, 'lambda': 3.3323645788192616e-08, 'alpha': 0.6245760287469893}. Best is trial 0 with value: 0.44681722167419224.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:53:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:54:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:54:25,174] Trial 1 finished with value: 0.4492806548792534 and parameters: {'eta': 0.06054365855469246, 'max_depth': 10, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'min_child_weight': 166.65608551928392, 'gamma': 1.0616955533913808, 'lambda': 4.329370014459266e-07, 'alpha': 4.4734294104626844e-07}. Best is trial 1 with value: 0.4492806548792534.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:54:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:55:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:55:03,359] Trial 2 finished with value: 0.4544460936078936 and parameters: {'eta': 0.024878734419814436, 'max_depth': 8, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'min_child_weight': 122.75872604975352, 'gamma': 0.6974693032602092, 'lambda': 4.258943089524393e-06, 'alpha': 1.9826980964985924e-05}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:55:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:55:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:55:58,951] Trial 3 finished with value: 0.45136099950481723 and parameters: {'eta': 0.03920673972242137, 'max_depth': 11, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'min_child_weight': 118.89049920354645, 'gamma': 0.23225206359998862, 'lambda': 0.0029369981104377003, 'alpha': 3.425445902633376e-07}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:55:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:57:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:57:24,777] Trial 4 finished with value: 0.4537527378208739 and parameters: {'eta': 0.012151617026673379, 'max_depth': 12, 'subsample': 0.9862528132298237, 'colsample_bytree': 0.9233589392465844, 'min_child_weight': 61.61814006550077, 'gamma': 0.48836057003191935, 'lambda': 0.014391207615728067, 'alpha': 9.148975058772307e-05}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:57:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:58:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:58:06,568] Trial 5 finished with value: 0.45310185102808265 and parameters: {'eta': 0.014413697528610409, 'max_depth': 8, 'subsample': 0.6137554084460873, 'colsample_bytree': 0.9637281608315128, 'min_child_weight': 52.49721633840337, 'gamma': 3.31261142176991, 'lambda': 6.388511557344611e-06, 'alpha': 0.0004793052550782129}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:58:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:58:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:58:31,215] Trial 6 finished with value: 0.4520505779349928 and parameters: {'eta': 0.05143828405076928, 'max_depth': 5, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'min_child_weight': 187.96028937127363, 'gamma': 4.474136752138244, 'lambda': 0.002404915432737351, 'alpha': 1.9809253750493907}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:58:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:58:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:58:59,231] Trial 7 finished with value: 0.4471382818028543 and parameters: {'eta': 0.01303561122512888, 'max_depth': 5, 'subsample': 0.6180909155642152, 'colsample_bytree': 0.7301321323053057, 'min_child_weight': 78.34678064820692, 'gamma': 1.3567451588694794, 'lambda': 0.28749982347407854, 'alpha': 1.6247252885719427e-05}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:58:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [18:59:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 18:59:38,761] Trial 8 finished with value: 0.45357596617926893 and parameters: {'eta': 0.023200867504756827, 'max_depth': 8, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'min_child_weight': 15.835578092274394, 'gamma': 4.9344346830025865, 'lambda': 0.08916674715636537, 'alpha': 6.143857495033091e-07}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [18:59:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:00:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:00:47,245] Trial 9 finished with value: 0.4543690477538108 and parameters: {'eta': 0.010166803740022877, 'max_depth': 11, 'subsample': 0.8827429375390468, 'colsample_bytree': 0.8916028672163949, 'min_child_weight': 154.4827989905032, 'gamma': 0.3702232586704518, 'lambda': 1.683416412018213e-05, 'alpha': 1.1036250149900698e-07}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:00:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:01:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:01:18,391] Trial 10 finished with value: 0.4471467149001803 and parameters: {'eta': 0.13388899274129873, 'max_depth': 7, 'subsample': 0.747491509088439, 'colsample_bytree': 0.6071847502459279, 'min_child_weight': 114.29318802780793, 'gamma': 2.215398984003511, 'lambda': 4.3444691085504115, 'alpha': 0.010039786460205685}. Best is trial 2 with value: 0.4544460936078936.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:01:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:02:02,098] Trial 11 finished with value: 0.45476081396283397 and parameters: {'eta': 0.0208199079003067, 'max_depth': 9, 'subsample': 0.8602591238708546, 'colsample_bytree': 0.7078349435778689, 'min_child_weight': 143.57776615043338, 'gamma': 1.9947625073276951, 'lambda': 2.8557889225697404e-05, 'alpha': 1.3835903921068856e-08}. Best is trial 11 with value: 0.45476081396283397.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:02:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:02:44,968] Trial 12 finished with value: 0.4548379711906828 and parameters: {'eta': 0.024506540460742583, 'max_depth': 9, 'subsample': 0.7997713546552523, 'colsample_bytree': 0.7136679613485023, 'min_child_weight': 141.81570952292964, 'gamma': 1.8161520771017918, 'lambda': 5.610661224399173e-05, 'alpha': 0.0074839487022762205}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:02:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:03:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:03:28,962] Trial 13 finished with value: 0.4458568366493677 and parameters: {'eta': 0.08321147917745453, 'max_depth': 10, 'subsample': 0.8503156423053643, 'colsample_bytree': 0.6908556046603515, 'min_child_weight': 134.8206667316769, 'gamma': 2.089971812464393, 'lambda': 8.773472263092466e-05, 'alpha': 0.01675663828360937}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:03:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:04:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:04:12,980] Trial 14 finished with value: 0.45444630855914786 and parameters: {'eta': 0.01926959116895896, 'max_depth': 9, 'subsample': 0.8241083667662439, 'colsample_bytree': 0.6447904467992578, 'min_child_weight': 195.2787882929842, 'gamma': 2.9634314695482455, 'lambda': 0.00014422243561458016, 'alpha': 0.008587026492761735}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:04:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:04:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:04:41,599] Trial 15 finished with value: 0.4531535981816328 and parameters: {'eta': 0.03495340099218811, 'max_depth': 6, 'subsample': 0.9251691820896131, 'colsample_bytree': 0.7599922797534859, 'min_child_weight': 91.01293626264408, 'gamma': 1.9132121420068722, 'lambda': 2.9890003885933953e-07, 'alpha': 1.0705353373434953e-08}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:04:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:05:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:05:25,859] Trial 16 finished with value: 0.4545028815893818 and parameters: {'eta': 0.01952917846781371, 'max_depth': 9, 'subsample': 0.7281904841416579, 'colsample_bytree': 0.6595968801681172, 'min_child_weight': 152.45112288054958, 'gamma': 2.997509191284597, 'lambda': 0.0005626454951351039, 'alpha': 0.2818936773599525}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:05:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:05:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:05:56,902] Trial 17 finished with value: 0.4523737520415958 and parameters: {'eta': 0.07972387552062825, 'max_depth': 7, 'subsample': 0.7995380778076538, 'colsample_bytree': 0.8002869483701581, 'min_child_weight': 170.56088324475772, 'gamma': 1.5757629929774808, 'lambda': 1.3140531432759214e-08, 'alpha': 0.0003433577182954456}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:05:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:06:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:06:20,669] Trial 18 finished with value: 0.44464249596419003 and parameters: {'eta': 0.016275128271199396, 'max_depth': 4, 'subsample': 0.9343632755267294, 'colsample_bytree': 0.7490723371733558, 'min_child_weight': 140.86603723663328, 'gamma': 3.637245390476013, 'lambda': 1.8213424611458964e-06, 'alpha': 0.05543957078034011}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:06:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:07:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:07:02,904] Trial 19 finished with value: 0.45467117594235307 and parameters: {'eta': 0.028283985907583763, 'max_depth': 9, 'subsample': 0.8399870475394532, 'colsample_bytree': 0.6834944140801354, 'min_child_weight': 101.31828954795083, 'gamma': 2.5072850771118333, 'lambda': 2.6479198906425803e-05, 'alpha': 0.0021738166616006873}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:07:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:07:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:07:48,029] Trial 20 finished with value: 0.4530241156517528 and parameters: {'eta': 0.04591804604815102, 'max_depth': 10, 'subsample': 0.7936986376091497, 'colsample_bytree': 0.6124902624472158, 'min_child_weight': 174.54483654522284, 'gamma': 3.9514249039405422, 'lambda': 0.0006336825029472525, 'alpha': 1.0736644845690471e-05}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:07:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:08:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:08:30,886] Trial 21 finished with value: 0.45459852364714337 and parameters: {'eta': 0.025790486190622845, 'max_depth': 9, 'subsample': 0.8506069966101463, 'colsample_bytree': 0.6789576558191524, 'min_child_weight': 97.75472025973767, 'gamma': 2.522207158689229, 'lambda': 4.013931320459628e-05, 'alpha': 0.001261058268350273}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:08:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:09:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:09:12,737] Trial 22 finished with value: 0.4546307686320113 and parameters: {'eta': 0.029172252230149968, 'max_depth': 9, 'subsample': 0.8350531418071546, 'colsample_bytree': 0.7075945952963482, 'min_child_weight': 137.23768675749668, 'gamma': 2.782230730937819, 'lambda': 3.112782846426791e-05, 'alpha': 0.003289728676306987}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:09:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:09:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:09:47,190] Trial 23 finished with value: 0.45348893908700705 and parameters: {'eta': 0.02221760245715791, 'max_depth': 7, 'subsample': 0.8816753902490096, 'colsample_bytree': 0.6455502589368015, 'min_child_weight': 108.08894327505817, 'gamma': 1.6923117184317544, 'lambda': 2.874860430308671e-07, 'alpha': 8.038061038966326}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:09:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:10:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:10:49,797] Trial 24 finished with value: 0.45435444769162675 and parameters: {'eta': 0.01844937530793947, 'max_depth': 11, 'subsample': 0.7267340845030492, 'colsample_bytree': 0.7697111240605155, 'min_child_weight': 82.4690078028431, 'gamma': 2.342747260448714, 'lambda': 1.7169470949239342e-06, 'alpha': 0.09015118712751338}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:10:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:11:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:11:24,499] Trial 25 finished with value: 0.43434500262705805 and parameters: {'eta': 0.19957713696355242, 'max_depth': 8, 'subsample': 0.7694698536265424, 'colsample_bytree': 0.6759478581463236, 'min_child_weight': 151.71943741457568, 'gamma': 1.2175500580059706, 'lambda': 0.0003064702485612882, 'alpha': 5.31956200765716e-05}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:11:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:12:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:12:11,747] Trial 26 finished with value: 0.45306213835671283 and parameters: {'eta': 0.03533865004191268, 'max_depth': 10, 'subsample': 0.933977695405836, 'colsample_bytree': 0.8473507878717289, 'min_child_weight': 69.5017035279534, 'gamma': 1.8710946624354436, 'lambda': 0.0031564530722047656, 'alpha': 2.1151882397141562e-06}. Best is trial 12 with value: 0.4548379711906828.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:12:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:12:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:12:53,704] Trial 27 finished with value: 0.4549001805545271 and parameters: {'eta': 0.029536343180881365, 'max_depth': 9, 'subsample': 0.8257506993458369, 'colsample_bytree': 0.7327771584656574, 'min_child_weight': 131.0133336642869, 'gamma': 2.6796064398970385, 'lambda': 5.475752539719283e-06, 'alpha': 1.9114643538472925e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:12:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:13:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:13:29,040] Trial 28 finished with value: 0.45295998087792333 and parameters: {'eta': 0.06082394338755319, 'max_depth': 8, 'subsample': 0.8104655409497706, 'colsample_bytree': 0.7741686384095295, 'min_child_weight': 127.6698713727679, 'gamma': 3.3834500477731413, 'lambda': 6.933413637821243e-08, 'alpha': 1.344490482632752e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:13:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:14:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:14:31,109] Trial 29 finished with value: 0.4519841444188225 and parameters: {'eta': 0.03440063622144526, 'max_depth': 12, 'subsample': 0.8989042973641793, 'colsample_bytree': 0.825467878984111, 'min_child_weight': 147.54499644505756, 'gamma': 0.9648620626831915, 'lambda': 8.597708016574533e-06, 'alpha': 5.0908501193005535e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:14:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:15:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:15:23,388] Trial 30 finished with value: 0.4547149587428503 and parameters: {'eta': 0.015532338680723125, 'max_depth': 10, 'subsample': 0.8691384758364996, 'colsample_bytree': 0.7452490250707724, 'min_child_weight': 178.79024451807172, 'gamma': 1.4111214742873708, 'lambda': 1.1544959676962333e-06, 'alpha': 2.412430431608682e-06}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:15:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:16:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:16:14,887] Trial 31 finished with value: 0.4547007157025477 and parameters: {'eta': 0.01688029221804149, 'max_depth': 10, 'subsample': 0.8796902735870226, 'colsample_bytree': 0.7355855622961766, 'min_child_weight': 163.22620422213743, 'gamma': 1.4311375693010528, 'lambda': 1.119422364209327e-06, 'alpha': 7.305764692743978e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:16:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:17:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:17:22,018] Trial 32 finished with value: 0.45429090153759666 and parameters: {'eta': 0.010045164609679236, 'max_depth': 11, 'subsample': 0.854684867605465, 'colsample_bytree': 0.7137268621791049, 'min_child_weight': 179.81302480565503, 'gamma': 1.8505572215812647, 'lambda': 6.713612372003555e-08, 'alpha': 2.6716875413515744e-06}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:17:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:18:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:18:11,892] Trial 33 finished with value: 0.45464079486104325 and parameters: {'eta': 0.02270200948929485, 'max_depth': 10, 'subsample': 0.7722106242439133, 'colsample_bytree': 0.7858815153767024, 'min_child_weight': 159.3734924759866, 'gamma': 0.9455562690142074, 'lambda': 5.849188322093072e-07, 'alpha': 4.1623256000986466e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:18:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:18:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:18:57,997] Trial 34 finished with value: 0.45418368156033173 and parameters: {'eta': 0.014955539030146799, 'max_depth': 9, 'subsample': 0.9107471296704781, 'colsample_bytree': 0.7427723159218897, 'min_child_weight': 124.67337251632962, 'gamma': 0.04500769313936548, 'lambda': 3.865119503128714e-06, 'alpha': 4.972205804388983e-07}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:18:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:19:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:19:36,477] Trial 35 finished with value: 0.45426493898809783 and parameters: {'eta': 0.021032574554814422, 'max_depth': 8, 'subsample': 0.8696526290686442, 'colsample_bytree': 0.7066897268700185, 'min_child_weight': 182.84334150398564, 'gamma': 0.7396287993916673, 'lambda': 8.063963667610581e-05, 'alpha': 1.7054682046744205e-07}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:19:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:20:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:20:28,192] Trial 36 finished with value: 0.45306025691488705 and parameters: {'eta': 0.04177477570650925, 'max_depth': 11, 'subsample': 0.8227364086941008, 'colsample_bytree': 0.7305222659108054, 'min_child_weight': 194.83479207612038, 'gamma': 2.6803938670283274, 'lambda': 8.737199244361217e-06, 'alpha': 2.68167101472815e-06}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:20:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:21:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:21:15,731] Trial 37 finished with value: 0.45365786294740096 and parameters: {'eta': 0.012377763215487943, 'max_depth': 9, 'subsample': 0.781738385444206, 'colsample_bytree': 0.8290973248460497, 'min_child_weight': 166.08542551192753, 'gamma': 2.1570577731548073, 'lambda': 2.8194254413800395e-06, 'alpha': 2.4878894895930366e-08}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:21:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:22:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:22:04,789] Trial 38 finished with value: 0.4546724630037787 and parameters: {'eta': 0.026614000381237058, 'max_depth': 10, 'subsample': 0.7534290426965986, 'colsample_bytree': 0.701652745559769, 'min_child_weight': 131.83857452397348, 'gamma': 1.2897799315881662, 'lambda': 1.168247798142523e-07, 'alpha': 0.00010159818643411898}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:22:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:22:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:22:40,413] Trial 39 finished with value: 0.4521251691554622 and parameters: {'eta': 0.014695417544048288, 'max_depth': 7, 'subsample': 0.9554477427050652, 'colsample_bytree': 0.8563722565108323, 'min_child_weight': 117.40800657960251, 'gamma': 1.6223158094288854, 'lambda': 0.00026629376710845577, 'alpha': 7.719770751209718e-07}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:22:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:23:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:23:40,504] Trial 40 finished with value: 0.4508107331368322 and parameters: {'eta': 0.031646475275688056, 'max_depth': 11, 'subsample': 0.7038631468359318, 'colsample_bytree': 0.6568421432064188, 'min_child_weight': 46.750307219861995, 'gamma': 2.945181250404353, 'lambda': 0.0017087239546965506, 'alpha': 1.4318905576102537e-07}. Best is trial 27 with value: 0.4549001805545271.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:23:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:24:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:24:31,863] Trial 41 finished with value: 0.4549019214486575 and parameters: {'eta': 0.017338342289964715, 'max_depth': 10, 'subsample': 0.8654068260730536, 'colsample_bytree': 0.7405054666091975, 'min_child_weight': 165.8462000112805, 'gamma': 1.406100452422435, 'lambda': 1.1694191607397867e-06, 'alpha': 4.626168740994528e-08}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:24:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:25:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:25:17,015] Trial 42 finished with value: 0.45449453927689687 and parameters: {'eta': 0.017333724458731905, 'max_depth': 9, 'subsample': 0.8132987673131348, 'colsample_bytree': 0.7248517189248735, 'min_child_weight': 139.64117631325783, 'gamma': 0.6105315313450346, 'lambda': 1.2551354108046946e-05, 'alpha': 2.579441451221393e-08}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:25:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:26:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:26:12,928] Trial 43 finished with value: 0.4544164266005892 and parameters: {'eta': 0.01172107092826572, 'max_depth': 10, 'subsample': 0.865700538411935, 'colsample_bytree': 0.7514830386040898, 'min_child_weight': 146.6661049587832, 'gamma': 1.1193073332456267, 'lambda': 6.208489239198009e-07, 'alpha': 1.5118510368498177e-07}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:26:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:27:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:27:48,950] Trial 44 finished with value: 0.4466731540134184 and parameters: {'eta': 0.01357473798619127, 'max_depth': 12, 'subsample': 0.8991625072405159, 'colsample_bytree': 0.7740072974660847, 'min_child_weight': 1.2885523467579247, 'gamma': 1.4641014212969417, 'lambda': 4.904923360817721e-06, 'alpha': 1.2015996911017925e-06}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:27:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:28:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:28:27,401] Trial 45 finished with value: 0.45395292848431623 and parameters: {'eta': 0.020682673905933615, 'max_depth': 8, 'subsample': 0.9652483726153429, 'colsample_bytree': 0.7841191020068704, 'min_child_weight': 173.699202690017, 'gamma': 2.050680391834306, 'lambda': 4.344124992731559e-05, 'alpha': 1.0381988378989093e-08}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:28:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:29:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:29:16,213] Trial 46 finished with value: 0.4547010976278929 and parameters: {'eta': 0.02501062245373449, 'max_depth': 10, 'subsample': 0.8335235696236885, 'colsample_bytree': 0.9643309908483702, 'min_child_weight': 185.01649385954883, 'gamma': 2.3482749953896036, 'lambda': 1.1668105957282148e-06, 'alpha': 7.601957684868928e-06}. Best is trial 41 with value: 0.4549019214486575.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:29:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:30:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:30:17,262] Trial 47 finished with value: 0.45497357054485527 and parameters: {'eta': 0.015743106541564272, 'max_depth': 11, 'subsample': 0.8587158659790564, 'colsample_bytree': 0.722007601926214, 'min_child_weight': 160.74462215946974, 'gamma': 1.8639721987878504, 'lambda': 1.5134184298893114e-05, 'alpha': 3.3302347766871394e-08}. Best is trial 47 with value: 0.45497357054485527.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:30:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:31:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:31:15,810] Trial 48 finished with value: 0.45482509095775564 and parameters: {'eta': 0.019333185279864787, 'max_depth': 11, 'subsample': 0.7969242839653238, 'colsample_bytree': 0.6247380403914914, 'min_child_weight': 159.0092650881804, 'gamma': 1.7243912417033864, 'lambda': 8.305519762106189e-05, 'alpha': 2.4920163387693835e-08}. Best is trial 47 with value: 0.45497357054485527.
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:31:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [19:32:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  return func(**kwargs)
[I 2025-10-16 19:32:32,242] Trial 49 finished with value: 0.4546202947019442 and parameters: {'eta': 0.011819556899981392, 'max_depth': 12, 'subsample': 0.7881097467903809, 'colsample_bytree': 0.6353394797910179, 'min_child_weight': 159.18095182225457, 'gamma': 1.7343161522066304, 'lambda': 0.01687634247597288, 'alpha': 2.487336897696838e-07}. Best is trial 47 with value: 0.45497357054485527.
[train_03] Best params: {'eta': 0.015743106541564272, 'max_depth': 11, 'subsample': 0.8587158659790564, 'colsample_bytree': 0.722007601926214, 'min_child_weight': 160.74462215946974, 'gamma': 1.8639721987878504, 'lambda': 1.5134184298893114e-05, 'alpha': 3.3302347766871394e-08, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0}
[train_03] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:32:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69066	valid-logloss:0.69071
[100]	train-logloss:0.58982	valid-logloss:0.59521
[200]	train-logloss:0.56736	valid-logloss:0.57696
[300]	train-logloss:0.55634	valid-logloss:0.56879
[400]	train-logloss:0.54915	valid-logloss:0.56375
[500]	train-logloss:0.54339	valid-logloss:0.55984
[600]	train-logloss:0.53824	valid-logloss:0.55638
[700]	train-logloss:0.53325	valid-logloss:0.55303
[800]	train-logloss:0.52857	valid-logloss:0.54995
[900]	train-logloss:0.52451	valid-logloss:0.54733
[999]	train-logloss:0.52028	valid-logloss:0.54458
[train_03] Model saved -> /content/drive/MyDrive/toss/model_train_03.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [19:33:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_03] Submission saved -> /content/drive/MyDrive/toss/submission_train_03.csv | shape=(1527298, 2)
=== END PIPELINE: train_03 ===

=== ALL DONE ===
{'train_01': {'model': '/content/drive/MyDrive/toss/model_train_01.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_01.csv'}, 'train_02': {'model': '/content/drive/MyDrive/toss/model_train_02.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_02.csv'}, 'train_03': {'model': '/content/drive/MyDrive/toss/model_train_03.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_03.csv'}}

## ìµœì¢…

# -----------------------
# í´ëž˜ìŠ¤ ê· í˜• ê°€ì¤‘ì¹˜
# -----------------------
def make_class_balanced_weights(y_true):
    n_pos = (y_true == 1).sum()
    n_neg = (y_true == 0).sum()
    w_pos = 0.5 / (n_pos if n_pos > 0 else 1)
    w_neg = 0.5 / (n_neg if n_neg > 0 else 1)
    return np.where(y_true == 1, w_pos, w_neg)

# -----------------------
# ì „ì²˜ë¦¬
# -----------------------
BASE_EXCLUDE = {"clicked", "ID", "seq"}

def preprocess(df, exclude_features=None):
    exclude = BASE_EXCLUDE.copy()
    if exclude_features:
        exclude |= set(exclude_features)
    X = df.drop(columns=[c for c in exclude if c in df.columns], errors="ignore")

    for col in X.select_dtypes(include="object").columns:
        X[col] = X[col].astype("category").cat.codes.astype("int32")
    for col in X.select_dtypes(include=["int64"]).columns:
        X[col] = X[col].astype("int32")
    for col in X.select_dtypes(include=["float64"]).columns:
        X[col] = X[col].astype("float32")
    return X

# -----------------------
# í•™ìŠµ+ì˜ˆì¸¡ í•¨ìˆ˜ (Optuna ì œê±°, í•˜ì´í¼íŒŒë¼ë¯¸í„° ì§ì ‘ ì ìš©)
# -----------------------
def train_and_predict_fixed_params(train_df, test_df, id_tag, seed, params):
    print(f"\n=== START PIPELINE: {id_tag} | seed={seed} ===")

    random.seed(seed)
    np.random.seed(seed)

    y = train_df["clicked"].astype(int).values.ravel()
    X = preprocess(train_df)
    X_test = preprocess(test_df)
    test_ids = test_df["ID"].values if "ID" in test_df.columns else np.arange(len(test_df))

    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=seed
    )

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dval = xgb.DMatrix(X_val, label=y_val)

    # ìµœì¢… í•™ìŠµ
    print(f"[{id_tag}] Training final model ...")
    model = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=[(dtrain, "train"), (dval, "valid")],
        early_stopping_rounds=50,
        verbose_eval=100
    )

    # ëª¨ë¸ ì €ìž¥
    model_path = os.path.join(DATA_PATH, f"model_{id_tag}.pkl")
    joblib.dump(model, model_path)
    print(f"[{id_tag}] Model saved -> {model_path} | best_iter={model.best_iteration}")

    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    dtest = xgb.DMatrix(X_test)
    preds = model.predict(dtest, iteration_range=(0, model.best_iteration + 1))
    sub = pd.DataFrame({"ID": test_ids, "clicked": preds})
    csv_path = os.path.join(DATA_PATH, f"submission_{id_tag}.csv")
    sub.to_csv(csv_path, index=False)
    print(f"[{id_tag}] Submission saved -> {csv_path} | shape={sub.shape}")
    print(f"=== END PIPELINE: {id_tag} ===\n")
    return model_path, csv_path

# -----------------------
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì§ì ‘ ì •ì˜
# -----------------------
fixed_params_list = [
    {
        'eta': 0.017157602606714745, 'max_depth': 10, 'subsample': 0.7374546934136761,
        'colsample_bytree': 0.62021628056724, 'min_child_weight': 166.4578793078511,
        'gamma': 2.5131209294713943, 'lambda': 6.22581603777314e-08,
        'alpha': 1.2152318879703765e-05, 'objective': 'binary:logistic',
        'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0
    },
    {
        'eta': 0.016271712241103357, 'max_depth': 11, 'subsample': 0.9451140044391817,
        'colsample_bytree': 0.707359562778431, 'min_child_weight': 140.26892309314096,
        'gamma': 0.14342296795415266, 'lambda': 0.004349553563477939,
        'alpha': 1.0213163630339229e-07, 'objective': 'binary:logistic',
        'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0
    },
    {
        'eta': 0.015743106541564272, 'max_depth': 11, 'subsample': 0.8587158659790564,
        'colsample_bytree': 0.722007601926214, 'min_child_weight': 160.74462215946974,
        'gamma': 1.8639721987878504, 'lambda': 1.5134184298893114e-05,
        'alpha': 3.3302347766871394e-08, 'objective': 'binary:logistic',
        'eval_metric': 'logloss', 'tree_method': 'gpu_hist', 'scale_pos_weight': 10.0
    }
]

# -----------------------
# ì‹¤í–‰
# -----------------------
datasets = [
    {"df": train_01, "id": "train_01", "seed": 106},
    {"df": train_02, "id": "train_02", "seed": 1031},
    {"df": train_03, "id": "train_03", "seed": 42},
]

results = {}
for i, data in enumerate(datasets):
    model_path, csv_path = train_and_predict_fixed_params(
        train_df=data["df"],
        test_df=test,
        id_tag=data["id"],
        seed=data["seed"],
        params=fixed_params_list[i]
    )
    results[data["id"]] = {"model": model_path, "submission": csv_path}

print("=== ALL DONE ===")
print(results)
=== START PIPELINE: train_01 | seed=106 ===
[train_01] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:39:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69052	valid-logloss:0.69056
[100]	train-logloss:0.59416	valid-logloss:0.59730
[200]	train-logloss:0.57572	valid-logloss:0.58169
[300]	train-logloss:0.56673	valid-logloss:0.57485
[400]	train-logloss:0.56077	valid-logloss:0.57051
[500]	train-logloss:0.55571	valid-logloss:0.56700
[600]	train-logloss:0.55156	valid-logloss:0.56423
[700]	train-logloss:0.54734	valid-logloss:0.56140
[800]	train-logloss:0.54341	valid-logloss:0.55879
[900]	train-logloss:0.53966	valid-logloss:0.55636
[999]	train-logloss:0.53625	valid-logloss:0.55416
[train_01] Model saved -> /content/drive/MyDrive/toss/model_train_01.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [19:40:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_01] Submission saved -> /content/drive/MyDrive/toss/submission_train_01.csv | shape=(1527298, 2)
=== END PIPELINE: train_01 ===


=== START PIPELINE: train_02 | seed=1031 ===
[train_02] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:41:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69049	valid-logloss:0.69057
[100]	train-logloss:0.58774	valid-logloss:0.59382
[200]	train-logloss:0.56435	valid-logloss:0.57525
[300]	train-logloss:0.55234	valid-logloss:0.56652
[400]	train-logloss:0.54517	valid-logloss:0.56155
[500]	train-logloss:0.53908	valid-logloss:0.55741
[600]	train-logloss:0.53375	valid-logloss:0.55386
[700]	train-logloss:0.52875	valid-logloss:0.55060
[800]	train-logloss:0.52412	valid-logloss:0.54757
[900]	train-logloss:0.51946	valid-logloss:0.54451
[999]	train-logloss:0.51507	valid-logloss:0.54165
[train_02] Model saved -> /content/drive/MyDrive/toss/model_train_02.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [19:42:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_02] Submission saved -> /content/drive/MyDrive/toss/submission_train_02.csv | shape=(1527298, 2)
=== END PIPELINE: train_02 ===


=== START PIPELINE: train_03 | seed=42 ===
[train_03] Training final model ...
/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:42:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  self.starting_round = model.num_boosted_rounds()
[0]	train-logloss:0.69066	valid-logloss:0.69071
[100]	train-logloss:0.58982	valid-logloss:0.59521
[200]	train-logloss:0.56736	valid-logloss:0.57696
[300]	train-logloss:0.55634	valid-logloss:0.56879
[400]	train-logloss:0.54915	valid-logloss:0.56375
[500]	train-logloss:0.54339	valid-logloss:0.55984
[600]	train-logloss:0.53824	valid-logloss:0.55638
[700]	train-logloss:0.53325	valid-logloss:0.55303
[800]	train-logloss:0.52857	valid-logloss:0.54995
[900]	train-logloss:0.52451	valid-logloss:0.54733
[999]	train-logloss:0.52028	valid-logloss:0.54458
[train_03] Model saved -> /content/drive/MyDrive/toss/model_train_03.pkl | best_iter=999
/usr/lib/python3.12/pickle.py:576: UserWarning: [19:43:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  rv = reduce(self.proto)
[train_03] Submission saved -> /content/drive/MyDrive/toss/submission_train_03.csv | shape=(1527298, 2)
=== END PIPELINE: train_03 ===

=== ALL DONE ===
{'train_01': {'model': '/content/drive/MyDrive/toss/model_train_01.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_01.csv'}, 'train_02': {'model': '/content/drive/MyDrive/toss/model_train_02.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_02.csv'}, 'train_03': {'model': '/content/drive/MyDrive/toss/model_train_03.pkl', 'submission': '/content/drive/MyDrive/toss/submission_train_03.csv'}}

# âœ… ê²½ë¡œ ì„¤ì •
drive_dir = "/content/drive/MyDrive/toss"
out_dir = "/content"

# âœ… 1) íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (Driveì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
df1 = pd.read_csv(os.path.join(drive_dir, "submission_train_01.csv"))
df2 = pd.read_csv(os.path.join(drive_dir, "submission_train_02.csv"))
df3 = pd.read_csv(os.path.join(drive_dir, "submission_train_03.csv"))

# âœ… 2) ID ê¸°ì¤€ ë³‘í•©
merged = df1.merge(df2, on="ID", suffixes=("_1", "_2"))
merged = merged.merge(df3, on="ID")
merged.rename(columns={"clicked": "clicked_3"}, inplace=True)

# âœ… 3) Soft Voting (í‰ê· )
merged["clicked"] = (
    merged["clicked_1"] + merged["clicked_2"] + merged["clicked_3"]
) / 3

# âœ… 4) IDì™€ ìµœì¢… clickedë§Œ ì¶”ì¶œ
final = merged[["ID", "clicked"]]

# âœ… 5) ì €ìž¥ (â†’ /content í´ë”ì— ì €ìž¥)
output_path = os.path.join(out_dir, "xgb.csv")
final.to_csv(output_path, index=False)

print(f"ðŸŽ¯ Soft Voting ê²°ê³¼ ì €ìž¥ ì™„ë£Œ!\níŒŒì¼ ê²½ë¡œ: {output_path}")
print(final.head())
ðŸŽ¯ Soft Voting ê²°ê³¼ ì €ìž¥ ì™„ë£Œ!
íŒŒì¼ ê²½ë¡œ: /content/xgb.csv
             ID   clicked
0  TEST_0000000  0.306297
1  TEST_0000001  0.289288
2  TEST_0000002  0.384673
3  TEST_0000003  0.440240
4  TEST_0000004  0.316747